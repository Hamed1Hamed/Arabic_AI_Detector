{
    "learning_rate": 0.001,
    "model_name": "aubmindlab/araelectra-base-discriminator",
    "epochs": 10,
    "batch_size": 64,
    "root_folder": "Dataset",
    "model_save_path": "saved_model",
    "final_model_path": "model_final_save",
    "checkpoint_path": "model_checkpoints",
    "patience": 10,
    "indicator_phrases_path": "chatGPT_words_ar.txt"
}
